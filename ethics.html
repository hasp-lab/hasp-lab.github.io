<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="description" content="cybersecurity research ">
	<meta name="HASP Lab" content="HASP Lab">
	<meta name="keywords" content="HASP, research, KCL, cybersecurity, artificial intelligence, privacy"> 


	<title>HASP</title>

	<!-- Bootstrap core CSS -->
	<link href="assets/css/bootstrap.css" rel="stylesheet">


	<!-- Custom styles for this template -->
	<link href="assets/css/main.css" rel="stylesheet">
	<script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
	<script src="assets/js/hover.zoom.js"></script>
	<script src="assets/js/hover.zoom.conf.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-SLF1XP512J"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'G-SLF1XP512J');
	</script>



	<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
  <![endif]-->
</head>


<body>
    <div class="ww">
        <!-- Static navbar -->
        <div class="navbar navbar-inverse navbar-static-top">
            <div class="header">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand"
                  href="index.html"><span
    style="color:#0288d1" class="fa fa-lock"> </span> HASP </a>
                 
                    <!-- <h2>"<i>History is a set of lies agreed upon.</i>" ~Napoleon Bonaparte</h2> -->
                </div>
                <div class="navbar-collapse collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li><a href="index.html">Welcome</a></li>
                        <li class="dropdown">
                            <button class="dropbtn navbar">Research</button>
                            <div class="dropdown-content">
                                <a href="privsec.html">AI Privacy and Security</a>
                                    <a
                                href="human.html">Human-centred
                                Privacy
                                and
                              Security</a>
                                <a href="multipriv.html">Multiuser Privacy</a>
                            
                              <a href="ethics.html">AI Ethics and Online Harms</a>
                            </div>
                        </li>
                        <li><a href="members.html">Members</a></li>
                        <li><a href="pubs.html">Publications</a></li>
                          </ul>
                     
                        </div><!--/.nav-collapse -->
                        <span style="color:white;font-size:10px;font-weight:bold;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Human-centred & AI Security,
                          Ethics and Privacy</span>
                      <!-- <h2>&nbsp;&nbsp;&nbsp;&nbsp;Human-centred & AI Security,
                          Ethics and Privacy</h2>-->
                          
                      </div>
                     
        </div>


    <div class="page">

  	
	<div class="row">
				<div class="  centered">
					<img width="40%" src="assets/img/portfolio/ethics-online-harm.jpg" alt="" >
				</div>
				<div class="  justified">
					
					<h3>AI Ethics and Online Harms </h3>
          
					<p>As more and more tasks and decisions are delegated to AI-enabled computers, mobile devices, and autonomous systems, it is crucial to understand the impacts this may have on people and that AI treats people ethically. Among other topics, we are working on:<br><br>
                    
                    1) Value-based and explainable AI, where we are developing AI models that are able to reason about human values, so that AI models act according to them. We also work on making AI models more transparent and explainable, so that users can better understand what they do and why. We have already proven that, in some specific recommendation domains, making AI value-aligned and explainable leads to more accpetable and satisfying recommendations. This also allows for a better way to scrutinise AI models in general.  <br><br>

					 2) AI Discrimination, where users may be treated unfairly or just differently based on their personal characteristics (e.g. gender, ethnicity, religion, etc.). Interestingly, AI very often reproduces existing instances of discrimination in the offline world by either inheriting the biases of prior decision makers, or simply reflecting widespread prejudices in society. Therefore, by developing methods to study AI discrimination, this also enables us to understand instances of human discrimination. For instance, we have applied our methods to discover biases in natural language processing models to discover dangerous prejudices in online communities using their own language (usually containing slang). </p>

					<p>Our research in this domain often involves cross-disciplinary collaborations, including colleagues from the social sciences, digital humanities, law, ethics and policy/governance.   </p>	
          			
          			<h5>Related Projects</h5>
          			<ul>
          				<li>Discovering and Attesting Digital Discrimination (EPSRC) - <a href="http://dadd-project.org/">DADD</a></li>
          				<li>National Research Centre on Privacy, Harm Reduction and Adversarial Influence Online (UKRI) - <a href="https://www.rephrain.ac.uk/">REPHRAIN</a></li>
          			</ul>
          			

          			<h5>Selected Publications </h5>
				<ul>
                    <li> Vahid Ghafouri,  Vibhor Agarwal,  Yong Zhang,  Nishanth Sastry,  Jose Such, and  Guillermo Suarez-Tangil.  AI in the Gray: Exploring Moderation Policies in Dialogic Large Language Models vs. Human Answers in Controversial Topics. In <i> The Conference on Information and Knowledge Management (CIKM)</i>, pp. In press., 2023.&nbsp;&nbsp;&nbsp;<a href="bibfiles/ghafouri2023ai.bib"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a>&nbsp;&nbsp;&nbsp;<a href="./pubs/ghafouri2023ai.pdf"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-file" aria-hidden="true"></span></a>&nbsp;</li>
                    <li> Mackenzie Jorgensen,  Hannah Richert,  Elizabeth Black,  Natalia Criado, and  Jose Such.  Not So Fair: The Impact of Presumably Fair Machine Learning Models. In <i> Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society (AIES)</i>, pp. 297–311, 2023.&nbsp;&nbsp;&nbsp;<a href="bibfiles/jorgensen2023not.bib"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a>&nbsp;&nbsp;&nbsp;<a href="./pubs/jorgensen2023not.pdf"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-file" aria-hidden="true"></span></a>&nbsp;</li>
				  <li> Xavier Ferrer,  Tom van Nuenen,
			    Jose Such, and  Natalia Criado.
			    Discovering and Interpreting Conceptual
			    Biases in Online Communities. <i> IEEE
			    Transactions on Knowledge and Data
			    Engineering (TKDE) </i>, 2021.&nbsp;&nbsp;&nbsp;<a href="bibfiles/ferrer2021discoveringtkde.bib"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a>&nbsp;&nbsp;&nbsp;<a href="./pubs/ferrer2021discoveringtkde.pdf"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-file" aria-hidden="true"></span></a>&nbsp;</li>

			    <li> Francesca Mosca and  Jose Such.  ELVIRA: an Explainable Agent for
                            Value and Utility-driven Multiuser Privacy. In <i>
                            International Joint Conference on Autonomous Agents and
                            Multiagent Systems (AAMAS)</i>, pp. 916&ndash;924,
                            2021.&nbsp;&nbsp;&nbsp;<a href="bibfiles/mosca2021elvira.bib"><span
                            style="font-size:15px;color:#2e86c1" class="glyphicon
                            glyphicon-pencil"
                            aria-hidden="true"></span></a>&nbsp;&nbsp;&nbsp;<a
                            href="./pubs/mosca2021elvira.pdf"><span
                            style="font-size:15px;color:#2e86c1" class="glyphicon
                            glyphicon-file" aria-hidden="true"></span></a>&nbsp;</li>
<li> Xavier Ferrer,  Tom van Nuenen,  Jose Such,  Mark Cote, and  Natalia Criado.  Bias and Discrimination in AI: a cross-disciplinary perspective. <i> IEEE Technology and Society</i>, 20(2):72–80, 2021.&nbsp;&nbsp;&nbsp;<a href="bibfiles/ferrer2021bias.bib"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a>&nbsp;&nbsp;&nbsp;<a href="./pubs/ferrer2021bias.pdf"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-file" aria-hidden="true"></span></a>&nbsp;</li>
<li> Xavier Ferrer,  Tom van Nuenen,  Jose Such, and  Natalia Criado.  Discovering and Categorising Language Biases in Reddit. In <i> The International AAAI Conference on Web and Social Media (ICWSM)</i>, 2021.&nbsp;&nbsp;&nbsp;<a href="bibfiles/ferrer2021discovering.bib"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a>&nbsp;&nbsp;&nbsp;<a href="./pubs/ferrer2021discovering.pdf"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-file" aria-hidden="true"></span></a>&nbsp;</li>
<li> Tom van Nuenen,  Xavier Ferrer,  Jose Such, and  Mark Cote.  Transparency for Whom? Assessing Discriminatory Artificial Intelligence. <i> IEEE Computer</i>,  53:36&ndash;44, 2020.&nbsp;&nbsp;&nbsp;<a href="bibfiles/vanNuenen2020transparency.bib"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-pencil" aria-hidden="true"></span></a>&nbsp;&nbsp;&nbsp;<a href="./pubs/vanNuenen2020transparency.pdf"><span style="font-size:15px;color:#2e86c1" class="glyphicon glyphicon-file" aria-hidden="true"></span></a>&nbsp;</li>
				  </ul>



<p> See more publications on this topic <a href="pubs.html#AI%20Ethics%20and%20Online%20Harms">here</a> </p>


				
				</div><!-- /col-lg-8 -->
			</div><!-- /row -->
	    </div> <!-- /page -->
	</div><!-- /ww -->
	
    </div>

	


    <!-- +++++ Footer Section +++++ -->
    <div class=footer_page>

    <div class="footer">
      <div class="footer_item">
       <img width="50%" src="assets/img/kcl.jpg"
        alt="" > </div>
            <div class="footer_item">
            <!--    <h4>Contact</h4> -->
             
              <p style="font-size:15px" align="center">
              Human-cented & AI Security, Ethics and Privacy<br>
                  HASP Lab <br>
                  <br>
                  <br>
              <!--Department of Informatics <br>
                    King's College London <br>
                    
                    Bush House, 30 Aldwych <br>
                    London, WC2B 4BG.-->
                </p>
                <p style="font-size:8px">
             <br>
              Website template based on <a
                    href="https://templatemag.com/stanley-bootstrap-freelancer-template/">
                    Stanley</a> template.
                    Images by <a
                    href="https://pixabay.com/users/thedigitalartist-202249/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3443628">Pete
                    </a> and <a
                    href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3994239">Gerd
                    Altmann</a> from <a
                    href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3994239">Pixabay</a>,
                     <a
                    href="https://www.flickr.com/photos/mikemacmarketing/30212411048/in/photostream/"> Mike
                    Mackenzie</a> and <a href="https://www.shutterstock.com/g/phonlamaiphoto">Phonlamai
                    Photo</a>.
                    <br>
                    
                </p>
            </div>
        <div class="footer_item">
          <img width="100%" src="assets/img/marca_UPV_principal_blanco150.png"
        alt="" >
        </div>
    
        </div>
    </div>


    <!-- Bootstrap core JavaScript
    	================================================== -->
    	<!-- Placed at the end of the document so the pages load faster -->
    	<script src="assets/js/bootstrap.min.js"></script>
    </body>
    </html>
